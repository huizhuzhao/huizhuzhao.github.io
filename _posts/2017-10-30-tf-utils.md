---
layout: post
title: TF-utils
date: 2017-03-25
---

## `tf.contrib.data.Dataset`
假设我们有 N 个样本, 对应的样本 ID 为 `{0, 1, 2, ..., N-1}`。我们使用 `tensorflow.contrib.data` 中的 `Dataset` 按顺序读入的数据，随后我们每次从中获取一个 `mini_batch` (大小为 `batch_size`)的样本，共获取 `N/batch_size`个`mini_batch`。因为数据是按照由小到大的顺序读入，因此获取数据的顺序同样由小到大，如下所示：

```
batch_0: {index_0+0, index_0+1, ..., index_0+batch_size-1}, index_0 = 0
batch_1: {index_1+0, index_1+1, ..., index_1+batch_size-1}, index_1 = batch_size * 1
...
batch_i: {index_i+0, index_i+1, ..., index_i+batch_size-1}, index_i = batch_size * (i-1)
...
```
现在我们使用 `Dataset.shuffle(buffer_size)` 方法对数据进行打乱，并测试 `buffer_size` 的大小对 `shuffle` 效果的影响。

理想情况下我们希望每次获取的 `batch_size` 个样本数据在原始顺序中尽可能的混乱。因此我们

1. 计算每个 `mini_batch` 中的样本位于原始序列中的 `batch_id = ID//batch_size`
2. 并统计 `batch_id` 的种类数作为混乱度 (`diversity`) 用来衡量混乱程度

比如当 `N=100, batch_size=10`, 某次获取的一个 `mini_batch` 数据的样本 ID 为 

`ID = {12, 10, 29, 40, 19, 19, 26, 76, 56, 20}`

则对应的 `batch_id` 和 `diversity` 为 

`batch_id = {1, 1, 2, 4, 1, 1, 2, 7, 5, 2}`

`diversity = len(set(batch_id)) = 5`。

通常情况下 `N >> batch_size`，因此 `diversity` 越接近 `batch_size` 表明混乱度越高。

如下图所示，我们取`N={1000, 2000, 4000, 8000, 16000, 20000, 32000}`,  `batch_size=100`, 对于每组 `(N, batch_size)`，测试 `buffer_size={1, batch_size, 2*batch_size, ..., factor*batch_size}` 其中 `factor = N//batch_size`

![](http://obmpvqs90.bkt.clouddn.com/tf_dataset_shuffle_buffer_size_1.png)
